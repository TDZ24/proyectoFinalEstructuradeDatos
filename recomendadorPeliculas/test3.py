import networkx as nx
import time
from tqdm import tqdm
import ollama

# ----------------------------
# GRAFO DE G√âNEROS Y PEL√çCULAS
# ----------------------------
G = nx.Graph()
generos = {
    "accion": [], "comedia": [], "drama": [], "terror": [],
    "ciencia ficcion": [], "romance": [], "aventura": [], "fantasia": []
}
for genero in generos:
    G.add_node(genero, tipo="genero")

# ----------------------------
# PREGUNTAS MEJORADAS
# ----------------------------
def hacer_preguntas():
    print("\nüé¨ Bienvenido al recomendador de pel√≠culas\n")
    puntos = {g: 0 for g in generos}
    
    preguntas = [
        ("¬øTe gustan escenas de acci√≥n intensas como 'John Wick'?", "accion", 2),
        ("¬øPrefieres comedias inteligentes tipo 'Los Bridgerton'?", "comedia", 1),
        ("¬øDisfrutas dramas profundos como 'El Padrino'?", "drama", 1.5),
        ("¬øBuscas sustos como en 'El Conjuro'?", "terror", 1),
        ("¬øTe interesa ciencia ficci√≥n como 'Interstellar'?", "ciencia ficcion", 1.5),
        ("¬øPrefieres romances realistas?", "romance", 1),
        ("¬øTe gustan aventuras como 'Indiana Jones'?", "aventura", 1),
        ("¬øAdoras fantas√≠a como 'El Se√±or de los Anillos'?", "fantasia", 2)
    ]

    for pregunta, genero, peso in preguntas:
        while True:
            respuesta = input(f"{pregunta} (si/no): ").lower().strip()
            if respuesta in ["si", "no"]:
                if respuesta == "si":
                    puntos[genero] += peso
                break
            print("‚ö†Ô∏è Responde solo 'si' o 'no'")

    max_puntos = max(puntos.values())
    generos_favoritos = [g for g, p in puntos.items() if p == max_puntos]
    
    if len(generos_favoritos) > 1:
        print(f"\nüî• Empate entre {', '.join(generos_favoritos)}")
        genero_favorito = input("Elige tu g√©nero preferido: ").lower()
    else:
        genero_favorito = generos_favoritos[0]
    
    return genero_favorito

# ----------------------------
# CONFIGURACI√ìN R√ÅPIDA
# ----------------------------
MODELO = "llama3"  # Modelo por defecto (usa :8b para versi√≥n ligera)
PROMPT = """Responde EN ESPA√ëOL. Recomienda 3 pel√≠culas de {genero} con:
1. **T√≠tulo** (A√±o)
- *Sinopsis:* Breve descripci√≥n
- *Por qu√© verla:* Raz√≥n personalizada"""

# ----------------------------
# FUNCI√ìN OPTIMIZADA
# ----------------------------
def recomendar_peliculas(genero):
    try:
        # Barra de progreso visual
        for _ in tqdm(range(15), desc="Buscando recomendaciones"):
            time.sleep(0.01)
        
        response = ollama.chat(
            model=MODELO,
            messages=[{
                "role": "user",
                "content": PROMPT.format(genero=genero)
            }],
            options={
                'temperature': 0.5,
                'num_predict': 250
            }
        )
        return response['message']['content']
    
    except Exception as e:
        return f"Error: {str(e)}\n‚ö†Ô∏è ¬øTienes Ollama instalado y el modelo descargado?"

# ----------------------------
# PROGRAMA PRINCIPAL
# ----------------------------
if __name__ == "__main__":
    # Verificaci√≥n inicial
    try:
        ollama.list()
    except:
        print("‚ùå Ollama no est√° corriendo. Ejecuta primero 'ollama serve'")
        exit()

    genero = hacer_preguntas()
    print(f"\nüéØ Tu g√©nero favorito: {genero.upper()}")
    
    start_time = time.time()
    recomendaciones = recomendar_peliculas(genero)
    
    print("\nüçø RECOMENDACIONES:")
    print(recomendaciones)
    print(f"\n‚è± Tiempo: {time.time() - start_time:.1f} segundos")